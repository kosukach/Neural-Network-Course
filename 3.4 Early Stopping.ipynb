{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n",
    "dummies = pd.get_dummies(df[\"species\"])\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "120/120 - 1s - loss: 1.1914 - val_loss: 1.1822\n",
      "Epoch 2/1000\n",
      "120/120 - 0s - loss: 1.0752 - val_loss: 1.0510\n",
      "Epoch 3/1000\n",
      "120/120 - 0s - loss: 0.9869 - val_loss: 0.9581\n",
      "Epoch 4/1000\n",
      "120/120 - 0s - loss: 0.9267 - val_loss: 0.8871\n",
      "Epoch 5/1000\n",
      "120/120 - 0s - loss: 0.8853 - val_loss: 0.8345\n",
      "Epoch 6/1000\n",
      "120/120 - 0s - loss: 0.8502 - val_loss: 0.7944\n",
      "Epoch 7/1000\n",
      "120/120 - 0s - loss: 0.8249 - val_loss: 0.7598\n",
      "Epoch 8/1000\n",
      "120/120 - 0s - loss: 0.7964 - val_loss: 0.7296\n",
      "Epoch 9/1000\n",
      "120/120 - 0s - loss: 0.7693 - val_loss: 0.7019\n",
      "Epoch 10/1000\n",
      "120/120 - 0s - loss: 0.7419 - val_loss: 0.6747\n",
      "Epoch 11/1000\n",
      "120/120 - 0s - loss: 0.7144 - val_loss: 0.6506\n",
      "Epoch 12/1000\n",
      "120/120 - 0s - loss: 0.6875 - val_loss: 0.6282\n",
      "Epoch 13/1000\n",
      "120/120 - 0s - loss: 0.6641 - val_loss: 0.6090\n",
      "Epoch 14/1000\n",
      "120/120 - 0s - loss: 0.6398 - val_loss: 0.5871\n",
      "Epoch 15/1000\n",
      "120/120 - 0s - loss: 0.6182 - val_loss: 0.5643\n",
      "Epoch 16/1000\n",
      "120/120 - 0s - loss: 0.5975 - val_loss: 0.5456\n",
      "Epoch 17/1000\n",
      "120/120 - 0s - loss: 0.5792 - val_loss: 0.5291\n",
      "Epoch 18/1000\n",
      "120/120 - 0s - loss: 0.5624 - val_loss: 0.5129\n",
      "Epoch 19/1000\n",
      "120/120 - 0s - loss: 0.5469 - val_loss: 0.4965\n",
      "Epoch 20/1000\n",
      "120/120 - 0s - loss: 0.5330 - val_loss: 0.4830\n",
      "Epoch 21/1000\n",
      "120/120 - 0s - loss: 0.5185 - val_loss: 0.4632\n",
      "Epoch 22/1000\n",
      "120/120 - 0s - loss: 0.5012 - val_loss: 0.4437\n",
      "Epoch 23/1000\n",
      "120/120 - 0s - loss: 0.4841 - val_loss: 0.4284\n",
      "Epoch 24/1000\n",
      "120/120 - 0s - loss: 0.4718 - val_loss: 0.4203\n",
      "Epoch 25/1000\n",
      "120/120 - 0s - loss: 0.4589 - val_loss: 0.4110\n",
      "Epoch 26/1000\n",
      "120/120 - 0s - loss: 0.4455 - val_loss: 0.3950\n",
      "Epoch 27/1000\n",
      "120/120 - 0s - loss: 0.4310 - val_loss: 0.3797\n",
      "Epoch 28/1000\n",
      "120/120 - 0s - loss: 0.4186 - val_loss: 0.3720\n",
      "Epoch 29/1000\n",
      "120/120 - 0s - loss: 0.4105 - val_loss: 0.3623\n",
      "Epoch 30/1000\n",
      "120/120 - 0s - loss: 0.4009 - val_loss: 0.3567\n",
      "Epoch 31/1000\n",
      "120/120 - 0s - loss: 0.3938 - val_loss: 0.3503\n",
      "Epoch 32/1000\n",
      "120/120 - 0s - loss: 0.3851 - val_loss: 0.3418\n",
      "Epoch 33/1000\n",
      "120/120 - 0s - loss: 0.3778 - val_loss: 0.3296\n",
      "Epoch 34/1000\n",
      "120/120 - 0s - loss: 0.3702 - val_loss: 0.3233\n",
      "Epoch 35/1000\n",
      "120/120 - 0s - loss: 0.3633 - val_loss: 0.3149\n",
      "Epoch 36/1000\n",
      "120/120 - 0s - loss: 0.3564 - val_loss: 0.3099\n",
      "Epoch 37/1000\n",
      "120/120 - 0s - loss: 0.3504 - val_loss: 0.3014\n",
      "Epoch 38/1000\n",
      "120/120 - 0s - loss: 0.3431 - val_loss: 0.2993\n",
      "Epoch 39/1000\n",
      "120/120 - 0s - loss: 0.3375 - val_loss: 0.2915\n",
      "Epoch 40/1000\n",
      "120/120 - 0s - loss: 0.3315 - val_loss: 0.2825\n",
      "Epoch 41/1000\n",
      "120/120 - 0s - loss: 0.3242 - val_loss: 0.2750\n",
      "Epoch 42/1000\n",
      "120/120 - 0s - loss: 0.3182 - val_loss: 0.2666\n",
      "Epoch 43/1000\n",
      "120/120 - 0s - loss: 0.3117 - val_loss: 0.2596\n",
      "Epoch 44/1000\n",
      "120/120 - 0s - loss: 0.3059 - val_loss: 0.2534\n",
      "Epoch 45/1000\n",
      "120/120 - 0s - loss: 0.2998 - val_loss: 0.2509\n",
      "Epoch 46/1000\n",
      "120/120 - 0s - loss: 0.2942 - val_loss: 0.2440\n",
      "Epoch 47/1000\n",
      "120/120 - 0s - loss: 0.2878 - val_loss: 0.2351\n",
      "Epoch 48/1000\n",
      "120/120 - 0s - loss: 0.2827 - val_loss: 0.2289\n",
      "Epoch 49/1000\n",
      "120/120 - 0s - loss: 0.2764 - val_loss: 0.2200\n",
      "Epoch 50/1000\n",
      "120/120 - 0s - loss: 0.2715 - val_loss: 0.2167\n",
      "Epoch 51/1000\n",
      "120/120 - 0s - loss: 0.2652 - val_loss: 0.2111\n",
      "Epoch 52/1000\n",
      "120/120 - 0s - loss: 0.2597 - val_loss: 0.2046\n",
      "Epoch 53/1000\n",
      "120/120 - 0s - loss: 0.2536 - val_loss: 0.2004\n",
      "Epoch 54/1000\n",
      "120/120 - 0s - loss: 0.2489 - val_loss: 0.1957\n",
      "Epoch 55/1000\n",
      "120/120 - 0s - loss: 0.2433 - val_loss: 0.1884\n",
      "Epoch 56/1000\n",
      "120/120 - 0s - loss: 0.2402 - val_loss: 0.1806\n",
      "Epoch 57/1000\n",
      "120/120 - 0s - loss: 0.2335 - val_loss: 0.1779\n",
      "Epoch 58/1000\n",
      "120/120 - 0s - loss: 0.2295 - val_loss: 0.1780\n",
      "Epoch 59/1000\n",
      "120/120 - 0s - loss: 0.2238 - val_loss: 0.1686\n",
      "Epoch 60/1000\n",
      "120/120 - 0s - loss: 0.2185 - val_loss: 0.1598\n",
      "Epoch 61/1000\n",
      "120/120 - 0s - loss: 0.2166 - val_loss: 0.1573\n",
      "Epoch 62/1000\n",
      "120/120 - 0s - loss: 0.2100 - val_loss: 0.1532\n",
      "Epoch 63/1000\n",
      "120/120 - 0s - loss: 0.2081 - val_loss: 0.1543\n",
      "Epoch 64/1000\n",
      "120/120 - 0s - loss: 0.2019 - val_loss: 0.1451\n",
      "Epoch 65/1000\n",
      "120/120 - 0s - loss: 0.1980 - val_loss: 0.1414\n",
      "Epoch 66/1000\n",
      "120/120 - 0s - loss: 0.1935 - val_loss: 0.1362\n",
      "Epoch 67/1000\n",
      "120/120 - 0s - loss: 0.1905 - val_loss: 0.1334\n",
      "Epoch 68/1000\n",
      "120/120 - 0s - loss: 0.1853 - val_loss: 0.1354\n",
      "Epoch 69/1000\n",
      "120/120 - 0s - loss: 0.1842 - val_loss: 0.1320\n",
      "Epoch 70/1000\n",
      "120/120 - 0s - loss: 0.1837 - val_loss: 0.1203\n",
      "Epoch 71/1000\n",
      "120/120 - 0s - loss: 0.1775 - val_loss: 0.1209\n",
      "Epoch 72/1000\n",
      "120/120 - 0s - loss: 0.1726 - val_loss: 0.1219\n",
      "Epoch 73/1000\n",
      "120/120 - 0s - loss: 0.1687 - val_loss: 0.1142\n",
      "Epoch 74/1000\n",
      "120/120 - 0s - loss: 0.1666 - val_loss: 0.1085\n",
      "Epoch 75/1000\n",
      "120/120 - 0s - loss: 0.1635 - val_loss: 0.1083\n",
      "Epoch 76/1000\n",
      "120/120 - 0s - loss: 0.1601 - val_loss: 0.1102\n",
      "Epoch 77/1000\n",
      "120/120 - 0s - loss: 0.1591 - val_loss: 0.1049\n",
      "Epoch 78/1000\n",
      "120/120 - 0s - loss: 0.1546 - val_loss: 0.1021\n",
      "Epoch 79/1000\n",
      "120/120 - 0s - loss: 0.1516 - val_loss: 0.0981\n",
      "Epoch 80/1000\n",
      "120/120 - 0s - loss: 0.1497 - val_loss: 0.0975\n",
      "Epoch 81/1000\n",
      "120/120 - 0s - loss: 0.1467 - val_loss: 0.0942\n",
      "Epoch 82/1000\n",
      "120/120 - 0s - loss: 0.1455 - val_loss: 0.0907\n",
      "Epoch 83/1000\n",
      "120/120 - 0s - loss: 0.1421 - val_loss: 0.0930\n",
      "Epoch 84/1000\n",
      "120/120 - 0s - loss: 0.1409 - val_loss: 0.0926\n",
      "Epoch 85/1000\n",
      "120/120 - 0s - loss: 0.1409 - val_loss: 0.0851\n",
      "Epoch 86/1000\n",
      "120/120 - 0s - loss: 0.1397 - val_loss: 0.0874\n",
      "Epoch 87/1000\n",
      "120/120 - 0s - loss: 0.1372 - val_loss: 0.0805\n",
      "Epoch 88/1000\n",
      "120/120 - 0s - loss: 0.1324 - val_loss: 0.0833\n",
      "Epoch 89/1000\n",
      "120/120 - 0s - loss: 0.1301 - val_loss: 0.0868\n",
      "Epoch 90/1000\n",
      "120/120 - 0s - loss: 0.1301 - val_loss: 0.0814\n",
      "Epoch 91/1000\n",
      "120/120 - 0s - loss: 0.1266 - val_loss: 0.0748\n",
      "Epoch 92/1000\n",
      "120/120 - 0s - loss: 0.1267 - val_loss: 0.0741\n",
      "Epoch 93/1000\n",
      "120/120 - 0s - loss: 0.1257 - val_loss: 0.0808\n",
      "Epoch 94/1000\n",
      "120/120 - 0s - loss: 0.1232 - val_loss: 0.0764\n",
      "Epoch 95/1000\n",
      "120/120 - 0s - loss: 0.1195 - val_loss: 0.0693\n",
      "Epoch 96/1000\n",
      "120/120 - 0s - loss: 0.1253 - val_loss: 0.0667\n",
      "Epoch 97/1000\n",
      "120/120 - 0s - loss: 0.1172 - val_loss: 0.0760\n",
      "Epoch 98/1000\n",
      "120/120 - 0s - loss: 0.1259 - val_loss: 0.0817\n",
      "Epoch 99/1000\n",
      "120/120 - 0s - loss: 0.1168 - val_loss: 0.0650\n",
      "Epoch 100/1000\n",
      "120/120 - 0s - loss: 0.1153 - val_loss: 0.0620\n",
      "Epoch 101/1000\n",
      "120/120 - 0s - loss: 0.1146 - val_loss: 0.0660\n",
      "Epoch 102/1000\n",
      "120/120 - 0s - loss: 0.1180 - val_loss: 0.0748\n",
      "Epoch 103/1000\n",
      "120/120 - 0s - loss: 0.1144 - val_loss: 0.0602\n",
      "Epoch 104/1000\n",
      "120/120 - 0s - loss: 0.1113 - val_loss: 0.0610\n",
      "Epoch 105/1000\n",
      "120/120 - 0s - loss: 0.1092 - val_loss: 0.0654\n",
      "Epoch 106/1000\n",
      "120/120 - 0s - loss: 0.1086 - val_loss: 0.0663\n",
      "Epoch 107/1000\n",
      "120/120 - 0s - loss: 0.1063 - val_loss: 0.0610\n",
      "Epoch 108/1000\n",
      "120/120 - 0s - loss: 0.1051 - val_loss: 0.0589\n",
      "Epoch 109/1000\n",
      "120/120 - 0s - loss: 0.1047 - val_loss: 0.0598\n",
      "Epoch 110/1000\n",
      "120/120 - 0s - loss: 0.1041 - val_loss: 0.0595\n",
      "Epoch 111/1000\n",
      "120/120 - 0s - loss: 0.1028 - val_loss: 0.0582\n",
      "Epoch 112/1000\n",
      "120/120 - 0s - loss: 0.1028 - val_loss: 0.0559\n",
      "Epoch 113/1000\n",
      "120/120 - 0s - loss: 0.1019 - val_loss: 0.0613\n",
      "Epoch 114/1000\n",
      "120/120 - 0s - loss: 0.1027 - val_loss: 0.0567\n",
      "Epoch 115/1000\n",
      "120/120 - 0s - loss: 0.0999 - val_loss: 0.0593\n",
      "Epoch 116/1000\n",
      "120/120 - 0s - loss: 0.0985 - val_loss: 0.0558\n",
      "Epoch 117/1000\n",
      "120/120 - 0s - loss: 0.0980 - val_loss: 0.0526\n",
      "Epoch 118/1000\n",
      "120/120 - 0s - loss: 0.0977 - val_loss: 0.0542\n",
      "Epoch 119/1000\n",
      "120/120 - 0s - loss: 0.0968 - val_loss: 0.0569\n",
      "Epoch 120/1000\n",
      "120/120 - 0s - loss: 0.1007 - val_loss: 0.0503\n",
      "Epoch 121/1000\n",
      "120/120 - 0s - loss: 0.0945 - val_loss: 0.0567\n",
      "Epoch 122/1000\n",
      "120/120 - 0s - loss: 0.0950 - val_loss: 0.0563\n",
      "Epoch 123/1000\n",
      "120/120 - 0s - loss: 0.0949 - val_loss: 0.0583\n",
      "Epoch 124/1000\n",
      "120/120 - 0s - loss: 0.0929 - val_loss: 0.0514\n",
      "Epoch 125/1000\n",
      "120/120 - 0s - loss: 0.0959 - val_loss: 0.0458\n",
      "Epoch 126/1000\n",
      "120/120 - 0s - loss: 0.0929 - val_loss: 0.0505\n",
      "Epoch 127/1000\n",
      "120/120 - 0s - loss: 0.0943 - val_loss: 0.0568\n",
      "Epoch 128/1000\n",
      "120/120 - 0s - loss: 0.0911 - val_loss: 0.0504\n",
      "Epoch 129/1000\n",
      "120/120 - 0s - loss: 0.0900 - val_loss: 0.0469\n",
      "Epoch 130/1000\n",
      "120/120 - 0s - loss: 0.0902 - val_loss: 0.0483\n",
      "Epoch 00130: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13789c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(25, activation=\"relu\"))\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "monitor = EarlyStopping(monitor=\"val_loss\", min_delta=1e-3, patience=5, verbose=1, mode=\"auto\")\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test), callbacks=[monitor], verbose=2, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "predict_classes = np.argmax(pred, axis=1)\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "correct = accuracy_score(true_classes, predict_classes)\n",
    "print(f\"Accuracy {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "reg_df['horsepower'] = reg_df['horsepower'].fillna(reg_df['horsepower'].median())\n",
    "x = reg_df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = reg_df['mpg'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "298/298 - 0s - loss: 146315.8402 - val_loss: 44593.8747\n",
      "Epoch 2/1000\n",
      "298/298 - 0s - loss: 16848.7668 - val_loss: 1003.6953\n",
      "Epoch 3/1000\n",
      "298/298 - 0s - loss: 3482.7888 - val_loss: 6567.6425\n",
      "Epoch 4/1000\n",
      "298/298 - 0s - loss: 5873.5829 - val_loss: 3097.9180\n",
      "Epoch 5/1000\n",
      "298/298 - 0s - loss: 1772.1983 - val_loss: 997.6503\n",
      "Epoch 6/1000\n",
      "298/298 - 0s - loss: 1080.6861 - val_loss: 1370.6477\n",
      "Epoch 7/1000\n",
      "298/298 - 0s - loss: 1073.2142 - val_loss: 1019.3477\n",
      "Epoch 8/1000\n",
      "298/298 - 0s - loss: 890.5227 - val_loss: 968.9722\n",
      "Epoch 9/1000\n",
      "298/298 - 0s - loss: 887.1084 - val_loss: 953.4608\n",
      "Epoch 10/1000\n",
      "298/298 - 0s - loss: 856.9368 - val_loss: 965.4029\n",
      "Epoch 11/1000\n",
      "298/298 - 0s - loss: 859.1027 - val_loss: 952.6759\n",
      "Epoch 12/1000\n",
      "298/298 - 0s - loss: 856.2010 - val_loss: 930.2864\n",
      "Epoch 13/1000\n",
      "298/298 - 0s - loss: 839.9491 - val_loss: 932.5153\n",
      "Epoch 14/1000\n",
      "298/298 - 0s - loss: 834.0909 - val_loss: 917.0661\n",
      "Epoch 15/1000\n",
      "298/298 - 0s - loss: 823.7610 - val_loss: 904.6496\n",
      "Epoch 16/1000\n",
      "298/298 - 0s - loss: 816.5979 - val_loss: 896.9927\n",
      "Epoch 17/1000\n",
      "298/298 - 0s - loss: 807.2747 - val_loss: 894.7774\n",
      "Epoch 18/1000\n",
      "298/298 - 0s - loss: 798.5143 - val_loss: 879.2496\n",
      "Epoch 19/1000\n",
      "298/298 - 0s - loss: 792.2615 - val_loss: 865.9111\n",
      "Epoch 20/1000\n",
      "298/298 - 0s - loss: 783.3857 - val_loss: 857.9927\n",
      "Epoch 21/1000\n",
      "298/298 - 0s - loss: 772.6333 - val_loss: 851.8928\n",
      "Epoch 22/1000\n",
      "298/298 - 0s - loss: 766.2319 - val_loss: 838.9070\n",
      "Epoch 23/1000\n",
      "298/298 - 0s - loss: 754.2576 - val_loss: 829.1527\n",
      "Epoch 24/1000\n",
      "298/298 - 0s - loss: 745.9329 - val_loss: 821.9576\n",
      "Epoch 25/1000\n",
      "298/298 - 0s - loss: 736.4412 - val_loss: 805.8743\n",
      "Epoch 26/1000\n",
      "298/298 - 0s - loss: 728.4833 - val_loss: 794.1286\n",
      "Epoch 27/1000\n",
      "298/298 - 0s - loss: 718.5153 - val_loss: 784.9590\n",
      "Epoch 28/1000\n",
      "298/298 - 0s - loss: 708.7424 - val_loss: 774.9614\n",
      "Epoch 29/1000\n",
      "298/298 - 0s - loss: 700.9725 - val_loss: 763.7120\n",
      "Epoch 30/1000\n",
      "298/298 - 0s - loss: 690.5088 - val_loss: 753.8927\n",
      "Epoch 31/1000\n",
      "298/298 - 0s - loss: 680.1896 - val_loss: 744.1749\n",
      "Epoch 32/1000\n",
      "298/298 - 0s - loss: 673.1714 - val_loss: 728.6583\n",
      "Epoch 33/1000\n",
      "298/298 - 0s - loss: 664.0149 - val_loss: 722.7748\n",
      "Epoch 34/1000\n",
      "298/298 - 0s - loss: 650.4574 - val_loss: 709.0770\n",
      "Epoch 35/1000\n",
      "298/298 - 0s - loss: 642.9712 - val_loss: 696.5371\n",
      "Epoch 36/1000\n",
      "298/298 - 0s - loss: 631.9925 - val_loss: 685.0095\n",
      "Epoch 37/1000\n",
      "298/298 - 0s - loss: 622.8412 - val_loss: 673.4534\n",
      "Epoch 38/1000\n",
      "298/298 - 0s - loss: 611.5513 - val_loss: 663.0743\n",
      "Epoch 39/1000\n",
      "298/298 - 0s - loss: 604.8599 - val_loss: 651.1384\n",
      "Epoch 40/1000\n",
      "298/298 - 0s - loss: 604.0168 - val_loss: 639.7197\n",
      "Epoch 41/1000\n",
      "298/298 - 0s - loss: 582.6470 - val_loss: 638.0892\n",
      "Epoch 42/1000\n",
      "298/298 - 0s - loss: 574.6616 - val_loss: 617.7920\n",
      "Epoch 43/1000\n",
      "298/298 - 0s - loss: 564.9785 - val_loss: 607.3892\n",
      "Epoch 44/1000\n",
      "298/298 - 0s - loss: 555.9433 - val_loss: 597.4603\n",
      "Epoch 45/1000\n",
      "298/298 - 0s - loss: 555.1297 - val_loss: 591.4006\n",
      "Epoch 46/1000\n",
      "298/298 - 0s - loss: 535.9645 - val_loss: 575.8537\n",
      "Epoch 47/1000\n",
      "298/298 - 0s - loss: 528.8766 - val_loss: 567.8830\n",
      "Epoch 48/1000\n",
      "298/298 - 0s - loss: 518.2549 - val_loss: 554.5028\n",
      "Epoch 49/1000\n",
      "298/298 - 0s - loss: 509.9290 - val_loss: 544.8133\n",
      "Epoch 50/1000\n",
      "298/298 - 0s - loss: 500.8409 - val_loss: 543.0969\n",
      "Epoch 51/1000\n",
      "298/298 - 0s - loss: 490.2855 - val_loss: 523.5614\n",
      "Epoch 52/1000\n",
      "298/298 - 0s - loss: 482.9551 - val_loss: 514.6838\n",
      "Epoch 53/1000\n",
      "298/298 - 0s - loss: 478.1474 - val_loss: 503.4306\n",
      "Epoch 54/1000\n",
      "298/298 - 0s - loss: 467.1772 - val_loss: 497.6478\n",
      "Epoch 55/1000\n",
      "298/298 - 0s - loss: 455.8300 - val_loss: 483.6177\n",
      "Epoch 56/1000\n",
      "298/298 - 0s - loss: 445.7674 - val_loss: 474.1164\n",
      "Epoch 57/1000\n",
      "298/298 - 0s - loss: 443.9276 - val_loss: 471.4068\n",
      "Epoch 58/1000\n",
      "298/298 - 0s - loss: 433.3175 - val_loss: 454.1340\n",
      "Epoch 59/1000\n",
      "298/298 - 0s - loss: 418.8749 - val_loss: 453.2214\n",
      "Epoch 60/1000\n",
      "298/298 - 0s - loss: 414.1962 - val_loss: 435.1178\n",
      "Epoch 61/1000\n",
      "298/298 - 0s - loss: 404.2712 - val_loss: 425.5996\n",
      "Epoch 62/1000\n",
      "298/298 - 0s - loss: 401.5421 - val_loss: 417.6305\n",
      "Epoch 63/1000\n",
      "298/298 - 0s - loss: 391.8588 - val_loss: 407.4997\n",
      "Epoch 64/1000\n",
      "298/298 - 0s - loss: 378.3728 - val_loss: 399.5540\n",
      "Epoch 65/1000\n",
      "298/298 - 0s - loss: 370.3083 - val_loss: 389.8592\n",
      "Epoch 66/1000\n",
      "298/298 - 0s - loss: 362.3586 - val_loss: 384.4883\n",
      "Epoch 67/1000\n",
      "298/298 - 0s - loss: 358.1229 - val_loss: 371.9117\n",
      "Epoch 68/1000\n",
      "298/298 - 0s - loss: 346.7850 - val_loss: 364.2191\n",
      "Epoch 69/1000\n",
      "298/298 - 0s - loss: 341.6066 - val_loss: 354.8464\n",
      "Epoch 70/1000\n",
      "298/298 - 0s - loss: 331.9635 - val_loss: 346.7330\n",
      "Epoch 71/1000\n",
      "298/298 - 0s - loss: 324.4841 - val_loss: 338.4651\n",
      "Epoch 72/1000\n",
      "298/298 - 0s - loss: 317.9644 - val_loss: 330.7638\n",
      "Epoch 73/1000\n",
      "298/298 - 0s - loss: 310.8103 - val_loss: 322.6080\n",
      "Epoch 74/1000\n",
      "298/298 - 0s - loss: 305.3884 - val_loss: 317.3257\n",
      "Epoch 75/1000\n",
      "298/298 - 0s - loss: 307.5739 - val_loss: 307.7441\n",
      "Epoch 76/1000\n",
      "298/298 - 0s - loss: 289.4613 - val_loss: 301.4235\n",
      "Epoch 77/1000\n",
      "298/298 - 0s - loss: 284.3513 - val_loss: 293.9507\n",
      "Epoch 78/1000\n",
      "298/298 - 0s - loss: 279.3630 - val_loss: 285.8104\n",
      "Epoch 79/1000\n",
      "298/298 - 0s - loss: 275.1700 - val_loss: 278.9940\n",
      "Epoch 80/1000\n",
      "298/298 - 0s - loss: 263.9363 - val_loss: 276.6503\n",
      "Epoch 81/1000\n",
      "298/298 - 0s - loss: 259.3036 - val_loss: 265.3011\n",
      "Epoch 82/1000\n",
      "298/298 - 0s - loss: 256.1304 - val_loss: 260.0042\n",
      "Epoch 83/1000\n",
      "298/298 - 0s - loss: 248.0737 - val_loss: 251.9882\n",
      "Epoch 84/1000\n",
      "298/298 - 0s - loss: 241.7886 - val_loss: 246.0261\n",
      "Epoch 85/1000\n",
      "298/298 - 0s - loss: 235.9184 - val_loss: 239.4856\n",
      "Epoch 86/1000\n",
      "298/298 - 0s - loss: 230.3302 - val_loss: 233.5549\n",
      "Epoch 87/1000\n",
      "298/298 - 0s - loss: 225.0964 - val_loss: 228.2565\n",
      "Epoch 88/1000\n",
      "298/298 - 0s - loss: 220.5868 - val_loss: 222.0338\n",
      "Epoch 89/1000\n",
      "298/298 - 0s - loss: 215.2772 - val_loss: 215.5994\n",
      "Epoch 90/1000\n",
      "298/298 - 0s - loss: 208.7868 - val_loss: 210.2614\n",
      "Epoch 91/1000\n",
      "298/298 - 0s - loss: 204.4991 - val_loss: 204.6414\n",
      "Epoch 92/1000\n",
      "298/298 - 0s - loss: 200.5298 - val_loss: 199.4735\n",
      "Epoch 93/1000\n",
      "298/298 - 0s - loss: 195.4397 - val_loss: 194.4938\n",
      "Epoch 94/1000\n",
      "298/298 - 0s - loss: 190.5482 - val_loss: 188.9400\n",
      "Epoch 95/1000\n",
      "298/298 - 0s - loss: 186.7032 - val_loss: 183.4291\n",
      "Epoch 96/1000\n",
      "298/298 - 0s - loss: 180.5408 - val_loss: 178.6644\n",
      "Epoch 97/1000\n",
      "298/298 - 0s - loss: 180.6441 - val_loss: 173.6547\n",
      "Epoch 98/1000\n",
      "298/298 - 0s - loss: 175.0905 - val_loss: 168.8474\n",
      "Epoch 99/1000\n",
      "298/298 - 0s - loss: 167.3062 - val_loss: 165.6892\n",
      "Epoch 100/1000\n",
      "298/298 - 0s - loss: 164.2094 - val_loss: 159.8448\n",
      "Epoch 101/1000\n",
      "298/298 - 0s - loss: 160.2220 - val_loss: 155.5386\n",
      "Epoch 102/1000\n",
      "298/298 - 0s - loss: 156.0144 - val_loss: 151.3099\n",
      "Epoch 103/1000\n",
      "298/298 - 0s - loss: 155.1378 - val_loss: 147.5546\n",
      "Epoch 104/1000\n",
      "298/298 - 0s - loss: 151.2297 - val_loss: 143.4320\n",
      "Epoch 105/1000\n",
      "298/298 - 0s - loss: 144.7395 - val_loss: 139.8794\n",
      "Epoch 106/1000\n",
      "298/298 - 0s - loss: 144.3236 - val_loss: 135.9732\n",
      "Epoch 107/1000\n",
      "298/298 - 0s - loss: 138.9146 - val_loss: 133.3726\n",
      "Epoch 108/1000\n",
      "298/298 - 0s - loss: 136.4843 - val_loss: 129.0144\n",
      "Epoch 109/1000\n",
      "298/298 - 0s - loss: 131.6378 - val_loss: 125.3610\n",
      "Epoch 110/1000\n",
      "298/298 - 0s - loss: 129.2196 - val_loss: 122.2110\n",
      "Epoch 111/1000\n",
      "298/298 - 0s - loss: 126.6147 - val_loss: 118.8652\n",
      "Epoch 112/1000\n",
      "298/298 - 0s - loss: 125.8929 - val_loss: 115.8338\n",
      "Epoch 113/1000\n",
      "298/298 - 0s - loss: 121.1431 - val_loss: 112.8642\n",
      "Epoch 114/1000\n",
      "298/298 - 0s - loss: 117.9722 - val_loss: 110.2560\n",
      "Epoch 115/1000\n",
      "298/298 - 0s - loss: 114.7418 - val_loss: 107.0572\n",
      "Epoch 116/1000\n",
      "298/298 - 0s - loss: 112.6834 - val_loss: 105.5764\n",
      "Epoch 117/1000\n",
      "298/298 - 0s - loss: 109.4728 - val_loss: 101.9390\n",
      "Epoch 118/1000\n",
      "298/298 - 0s - loss: 106.3786 - val_loss: 100.7689\n",
      "Epoch 119/1000\n",
      "298/298 - 0s - loss: 106.7589 - val_loss: 97.8230\n",
      "Epoch 120/1000\n",
      "298/298 - 0s - loss: 104.2526 - val_loss: 94.8332\n",
      "Epoch 121/1000\n",
      "298/298 - 0s - loss: 101.1111 - val_loss: 91.8232\n",
      "Epoch 122/1000\n",
      "298/298 - 0s - loss: 98.4740 - val_loss: 90.0196\n",
      "Epoch 123/1000\n",
      "298/298 - 0s - loss: 96.6800 - val_loss: 87.2171\n",
      "Epoch 124/1000\n",
      "298/298 - 0s - loss: 94.5960 - val_loss: 85.4803\n",
      "Epoch 125/1000\n",
      "298/298 - 0s - loss: 93.9099 - val_loss: 83.6058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000\n",
      "298/298 - 0s - loss: 91.1752 - val_loss: 81.1218\n",
      "Epoch 127/1000\n",
      "298/298 - 0s - loss: 90.4727 - val_loss: 81.2757\n",
      "Epoch 128/1000\n",
      "298/298 - 0s - loss: 91.0590 - val_loss: 77.5639\n",
      "Epoch 129/1000\n",
      "298/298 - 0s - loss: 85.8756 - val_loss: 76.5198\n",
      "Epoch 130/1000\n",
      "298/298 - 0s - loss: 83.6105 - val_loss: 74.0758\n",
      "Epoch 131/1000\n",
      "298/298 - 0s - loss: 82.7045 - val_loss: 72.3810\n",
      "Epoch 132/1000\n",
      "298/298 - 0s - loss: 80.4036 - val_loss: 71.6004\n",
      "Epoch 133/1000\n",
      "298/298 - 0s - loss: 79.0251 - val_loss: 69.2946\n",
      "Epoch 134/1000\n",
      "298/298 - 0s - loss: 77.2548 - val_loss: 68.5035\n",
      "Epoch 135/1000\n",
      "298/298 - 0s - loss: 76.4634 - val_loss: 66.8310\n",
      "Epoch 136/1000\n",
      "298/298 - 0s - loss: 75.3906 - val_loss: 65.7207\n",
      "Epoch 137/1000\n",
      "298/298 - 0s - loss: 73.7117 - val_loss: 64.5465\n",
      "Epoch 138/1000\n",
      "298/298 - 0s - loss: 72.4777 - val_loss: 63.0170\n",
      "Epoch 139/1000\n",
      "298/298 - 0s - loss: 72.0720 - val_loss: 62.1557\n",
      "Epoch 140/1000\n",
      "298/298 - 0s - loss: 70.9940 - val_loss: 60.3619\n",
      "Epoch 141/1000\n",
      "298/298 - 0s - loss: 68.8467 - val_loss: 60.6461\n",
      "Epoch 142/1000\n",
      "298/298 - 0s - loss: 68.9208 - val_loss: 59.2243\n",
      "Epoch 143/1000\n",
      "298/298 - 0s - loss: 66.8898 - val_loss: 57.9933\n",
      "Epoch 144/1000\n",
      "298/298 - 0s - loss: 67.4701 - val_loss: 57.1245\n",
      "Epoch 145/1000\n",
      "298/298 - 0s - loss: 65.2679 - val_loss: 55.4130\n",
      "Epoch 146/1000\n",
      "298/298 - 0s - loss: 64.0057 - val_loss: 54.7376\n",
      "Epoch 147/1000\n",
      "298/298 - 0s - loss: 63.4665 - val_loss: 54.8877\n",
      "Epoch 148/1000\n",
      "298/298 - 0s - loss: 63.1043 - val_loss: 53.5323\n",
      "Epoch 149/1000\n",
      "298/298 - 0s - loss: 61.7071 - val_loss: 52.1854\n",
      "Epoch 150/1000\n",
      "298/298 - 0s - loss: 61.2271 - val_loss: 52.5839\n",
      "Epoch 151/1000\n",
      "298/298 - 0s - loss: 61.6730 - val_loss: 50.4743\n",
      "Epoch 152/1000\n",
      "298/298 - 0s - loss: 59.8320 - val_loss: 51.3882\n",
      "Epoch 153/1000\n",
      "298/298 - 0s - loss: 58.9550 - val_loss: 49.0694\n",
      "Epoch 154/1000\n",
      "298/298 - 0s - loss: 57.9631 - val_loss: 49.3367\n",
      "Epoch 155/1000\n",
      "298/298 - 0s - loss: 59.8339 - val_loss: 48.3509\n",
      "Epoch 156/1000\n",
      "298/298 - 0s - loss: 58.8364 - val_loss: 49.8867\n",
      "Epoch 157/1000\n",
      "298/298 - 0s - loss: 57.4881 - val_loss: 47.5793\n",
      "Epoch 158/1000\n",
      "298/298 - 0s - loss: 57.2036 - val_loss: 58.7598\n",
      "Epoch 159/1000\n",
      "298/298 - 0s - loss: 59.7946 - val_loss: 48.3443\n",
      "Epoch 160/1000\n",
      "298/298 - 0s - loss: 58.9676 - val_loss: 45.6138\n",
      "Epoch 161/1000\n",
      "298/298 - 0s - loss: 55.7443 - val_loss: 46.1780\n",
      "Epoch 162/1000\n",
      "298/298 - 0s - loss: 53.5622 - val_loss: 43.9140\n",
      "Epoch 163/1000\n",
      "298/298 - 0s - loss: 52.8773 - val_loss: 44.6914\n",
      "Epoch 164/1000\n",
      "298/298 - 0s - loss: 52.1266 - val_loss: 43.0648\n",
      "Epoch 165/1000\n",
      "298/298 - 0s - loss: 52.1078 - val_loss: 44.5595\n",
      "Epoch 166/1000\n",
      "298/298 - 0s - loss: 52.1217 - val_loss: 42.1209\n",
      "Epoch 167/1000\n",
      "298/298 - 0s - loss: 50.6154 - val_loss: 43.3630\n",
      "Epoch 168/1000\n",
      "298/298 - 0s - loss: 50.6720 - val_loss: 41.6036\n",
      "Epoch 169/1000\n",
      "298/298 - 0s - loss: 50.1358 - val_loss: 40.9569\n",
      "Epoch 170/1000\n",
      "298/298 - 0s - loss: 49.7960 - val_loss: 43.0610\n",
      "Epoch 171/1000\n",
      "298/298 - 0s - loss: 52.2395 - val_loss: 41.0725\n",
      "Epoch 172/1000\n",
      "298/298 - 0s - loss: 51.6621 - val_loss: 40.3777\n",
      "Epoch 173/1000\n",
      "298/298 - 0s - loss: 49.2813 - val_loss: 40.7606\n",
      "Epoch 174/1000\n",
      "298/298 - 0s - loss: 48.8282 - val_loss: 39.5073\n",
      "Epoch 175/1000\n",
      "298/298 - 0s - loss: 48.4355 - val_loss: 39.2620\n",
      "Epoch 176/1000\n",
      "298/298 - 0s - loss: 47.8466 - val_loss: 39.1188\n",
      "Epoch 177/1000\n",
      "298/298 - 0s - loss: 47.9161 - val_loss: 38.4440\n",
      "Epoch 178/1000\n",
      "298/298 - 0s - loss: 48.2819 - val_loss: 45.5427\n",
      "Epoch 179/1000\n",
      "298/298 - 0s - loss: 52.9021 - val_loss: 39.9772\n",
      "Epoch 180/1000\n",
      "298/298 - 0s - loss: 49.0814 - val_loss: 37.8690\n",
      "Epoch 181/1000\n",
      "298/298 - 0s - loss: 46.4255 - val_loss: 39.1042\n",
      "Epoch 182/1000\n",
      "298/298 - 0s - loss: 45.5810 - val_loss: 37.3274\n",
      "Epoch 183/1000\n",
      "298/298 - 0s - loss: 47.1688 - val_loss: 42.1678\n",
      "Epoch 184/1000\n",
      "298/298 - 0s - loss: 45.4959 - val_loss: 36.6974\n",
      "Epoch 185/1000\n",
      "298/298 - 0s - loss: 44.5971 - val_loss: 37.4236\n",
      "Epoch 186/1000\n",
      "298/298 - 0s - loss: 44.5293 - val_loss: 36.7175\n",
      "Epoch 187/1000\n",
      "298/298 - 0s - loss: 45.4956 - val_loss: 37.4092\n",
      "Epoch 188/1000\n",
      "298/298 - 0s - loss: 43.8086 - val_loss: 35.6658\n",
      "Epoch 189/1000\n",
      "298/298 - 0s - loss: 43.9045 - val_loss: 36.1161\n",
      "Epoch 190/1000\n",
      "298/298 - 0s - loss: 43.7430 - val_loss: 37.6014\n",
      "Epoch 191/1000\n",
      "298/298 - 0s - loss: 45.9741 - val_loss: 35.1343\n",
      "Epoch 192/1000\n",
      "298/298 - 0s - loss: 43.1942 - val_loss: 35.2335\n",
      "Epoch 193/1000\n",
      "298/298 - 0s - loss: 44.2144 - val_loss: 38.1951\n",
      "Epoch 194/1000\n",
      "298/298 - 0s - loss: 43.3244 - val_loss: 35.9411\n",
      "Epoch 195/1000\n",
      "298/298 - 0s - loss: 43.1030 - val_loss: 35.3273\n",
      "Epoch 196/1000\n",
      "298/298 - 0s - loss: 41.9497 - val_loss: 34.0828\n",
      "Epoch 197/1000\n",
      "298/298 - 0s - loss: 41.6075 - val_loss: 34.7419\n",
      "Epoch 198/1000\n",
      "298/298 - 0s - loss: 41.7861 - val_loss: 33.6796\n",
      "Epoch 199/1000\n",
      "298/298 - 0s - loss: 40.5745 - val_loss: 35.4125\n",
      "Epoch 200/1000\n",
      "298/298 - 0s - loss: 40.5765 - val_loss: 33.2315\n",
      "Epoch 201/1000\n",
      "298/298 - 0s - loss: 40.9952 - val_loss: 33.8915\n",
      "Epoch 202/1000\n",
      "298/298 - 0s - loss: 40.6526 - val_loss: 33.8621\n",
      "Epoch 203/1000\n",
      "298/298 - 0s - loss: 40.4691 - val_loss: 34.2514\n",
      "Epoch 204/1000\n",
      "298/298 - 0s - loss: 40.2468 - val_loss: 32.7616\n",
      "Epoch 205/1000\n",
      "298/298 - 0s - loss: 39.8384 - val_loss: 33.6646\n",
      "Epoch 206/1000\n",
      "298/298 - 0s - loss: 39.5144 - val_loss: 32.4769\n",
      "Epoch 207/1000\n",
      "298/298 - 0s - loss: 39.3050 - val_loss: 32.0529\n",
      "Epoch 208/1000\n",
      "298/298 - 0s - loss: 39.0191 - val_loss: 39.2841\n",
      "Epoch 209/1000\n",
      "298/298 - 0s - loss: 42.3054 - val_loss: 34.6854\n",
      "Epoch 210/1000\n",
      "298/298 - 0s - loss: 39.1179 - val_loss: 38.4017\n",
      "Epoch 211/1000\n",
      "298/298 - 0s - loss: 39.6579 - val_loss: 31.3691\n",
      "Epoch 212/1000\n",
      "298/298 - 0s - loss: 38.2742 - val_loss: 31.1987\n",
      "Epoch 213/1000\n",
      "298/298 - 0s - loss: 38.5875 - val_loss: 32.6174\n",
      "Epoch 214/1000\n",
      "298/298 - 0s - loss: 39.9670 - val_loss: 31.3069\n",
      "Epoch 215/1000\n",
      "298/298 - 0s - loss: 40.9796 - val_loss: 33.3837\n",
      "Epoch 216/1000\n",
      "298/298 - 0s - loss: 40.8012 - val_loss: 50.5163\n",
      "Epoch 217/1000\n",
      "298/298 - 0s - loss: 43.0486 - val_loss: 30.4148\n",
      "Epoch 218/1000\n",
      "298/298 - 0s - loss: 37.3741 - val_loss: 30.2726\n",
      "Epoch 219/1000\n",
      "298/298 - 0s - loss: 37.4879 - val_loss: 32.9521\n",
      "Epoch 220/1000\n",
      "298/298 - 0s - loss: 37.4341 - val_loss: 31.4549\n",
      "Epoch 221/1000\n",
      "298/298 - 0s - loss: 36.5994 - val_loss: 31.0569\n",
      "Epoch 222/1000\n",
      "298/298 - 0s - loss: 36.4527 - val_loss: 31.6177\n",
      "Epoch 223/1000\n",
      "298/298 - 0s - loss: 37.9472 - val_loss: 29.8675\n",
      "Epoch 224/1000\n",
      "298/298 - 0s - loss: 36.9371 - val_loss: 30.9954\n",
      "Epoch 225/1000\n",
      "298/298 - 0s - loss: 38.5687 - val_loss: 33.0050\n",
      "Epoch 226/1000\n",
      "298/298 - 0s - loss: 36.5097 - val_loss: 30.9111\n",
      "Epoch 227/1000\n",
      "298/298 - 0s - loss: 36.7221 - val_loss: 29.0481\n",
      "Epoch 228/1000\n",
      "298/298 - 0s - loss: 35.5647 - val_loss: 28.8150\n",
      "Epoch 229/1000\n",
      "298/298 - 0s - loss: 35.4437 - val_loss: 28.6593\n",
      "Epoch 230/1000\n",
      "298/298 - 0s - loss: 35.1267 - val_loss: 28.6605\n",
      "Epoch 231/1000\n",
      "298/298 - 0s - loss: 34.5755 - val_loss: 28.6542\n",
      "Epoch 232/1000\n",
      "298/298 - 0s - loss: 34.6464 - val_loss: 32.8327\n",
      "Epoch 233/1000\n",
      "298/298 - 0s - loss: 36.6575 - val_loss: 28.9523\n",
      "Epoch 234/1000\n",
      "298/298 - 0s - loss: 36.2579 - val_loss: 29.4405\n",
      "Epoch 235/1000\n",
      "298/298 - 0s - loss: 37.8189 - val_loss: 33.3901\n",
      "Epoch 236/1000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "298/298 - 0s - loss: 36.0919 - val_loss: 30.7642\n",
      "Epoch 00236: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149d2688>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "monitor = EarlyStopping(monitor=\"val_loss\", min_delta=1e-3, patience=5, verbose=1, mode=\"auto\", restore_best_weights=True)\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[monitor], verbose=2, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
